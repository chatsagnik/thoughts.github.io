<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Self-Reducibility | Theoretickles</title><meta name=keywords content="reductions,p-np,eth,self-reducibility,search-to-decision,factoring,primality,TFNP"><meta name=description content="
This post assumes basic familiarity with Turing machines, P, NP, NP-completeness, decidability, and undecidability. The reader is referred to the book by Sipser, or the book by Arora and Barak for any formal definitions that have been skipped in this post. Without further ado, let&rsquo;s dive in.

Introduction
In an earlier post, we familiarised ourselves with the notion of reductions. Towards the end, we introduced the notion of self-reducibility which is our main topic of focus today. We start by familiarising ourselves with a few concepts."><meta name=author content="Me"><link rel=canonical href=https://theoretickles.netlify.app/posts/selfreductions/><link crossorigin=anonymous href=/assets/css/stylesheet.19b5e0d1f8f356af6c38fbd3c9618d76d111dd5fba9672efb310a2309683518a.css integrity="sha256-GbXg0fjzVq9sOPvTyWGNdtER3V+6lnLvsxCiMJaDUYo=" rel="preload stylesheet" as=style><link rel=icon href=https://theoretickles.netlify.app/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://theoretickles.netlify.app/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://theoretickles.netlify.app/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://theoretickles.netlify.app/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://theoretickles.netlify.app/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://theoretickles.netlify.app/posts/selfreductions/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=text/javascript id=MathJax-script async src=https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.0.0/es5/latest?tex-mml-chtml.js></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><meta property="og:url" content="https://theoretickles.netlify.app/posts/selfreductions/"><meta property="og:site_name" content="Theoretickles"><meta property="og:title" content="Self-Reducibility"><meta property="og:description" content=" This post assumes basic familiarity with Turing machines, P, NP, NP-completeness, decidability, and undecidability. The reader is referred to the book by Sipser, or the book by Arora and Barak for any formal definitions that have been skipped in this post. Without further ado, let’s dive in.
Introduction In an earlier post, we familiarised ourselves with the notion of reductions. Towards the end, we introduced the notion of self-reducibility which is our main topic of focus today. We start by familiarising ourselves with a few concepts."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-02-01T11:51:18+05:30"><meta property="article:modified_time" content="2025-02-01T11:51:18+05:30"><meta property="article:tag" content="Reductions"><meta property="article:tag" content="P-Np"><meta property="article:tag" content="Eth"><meta property="article:tag" content="Self-Reducibility"><meta property="article:tag" content="Search-to-Decision"><meta property="article:tag" content="Factoring"><meta property="og:image" content="https://theoretickles.netlify.app/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://theoretickles.netlify.app/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Self-Reducibility"><meta name=twitter:description content="
This post assumes basic familiarity with Turing machines, P, NP, NP-completeness, decidability, and undecidability. The reader is referred to the book by Sipser, or the book by Arora and Barak for any formal definitions that have been skipped in this post. Without further ado, let&rsquo;s dive in.

Introduction
In an earlier post, we familiarised ourselves with the notion of reductions. Towards the end, we introduced the notion of self-reducibility which is our main topic of focus today. We start by familiarising ourselves with a few concepts."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://theoretickles.netlify.app/posts/"},{"@type":"ListItem","position":2,"name":"Self-Reducibility","item":"https://theoretickles.netlify.app/posts/selfreductions/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Self-Reducibility","name":"Self-Reducibility","description":" This post assumes basic familiarity with Turing machines, P, NP, NP-completeness, decidability, and undecidability. The reader is referred to the book by Sipser, or the book by Arora and Barak for any formal definitions that have been skipped in this post. Without further ado, let\u0026rsquo;s dive in.\nIntroduction In an earlier post, we familiarised ourselves with the notion of reductions. Towards the end, we introduced the notion of self-reducibility which is our main topic of focus today. We start by familiarising ourselves with a few concepts.\n","keywords":["reductions","p-np","eth","self-reducibility","search-to-decision","factoring","primality","TFNP"],"articleBody":" This post assumes basic familiarity with Turing machines, P, NP, NP-completeness, decidability, and undecidability. The reader is referred to the book by Sipser, or the book by Arora and Barak for any formal definitions that have been skipped in this post. Without further ado, let’s dive in.\nIntroduction In an earlier post, we familiarised ourselves with the notion of reductions. Towards the end, we introduced the notion of self-reducibility which is our main topic of focus today. We start by familiarising ourselves with a few concepts.\nSearch-to-Decision Reductions In the world of complexity and computability, a language is a set of strings formed out of some alphabet. Formally, $L\\subseteq\\Sigma^{*}$, where the alphabet $\\Sigma$ is a finite set of symbols, and $\\Sigma^{*}$ refers to the Kleene closure of $\\Sigma$.\nLast time we formalized reductions in terms of Turing Machines. We now explicitly define mapping reductions (equivalent to Karp reductions for TMs) in terms of languages. Let $L_1 \\subseteq \\Sigma_1^{*}$ and $L_2 \\subseteq \\Sigma_2^{*}$ be languages. Recall that $L_1\\leq_m L_2$ (or, $L_1$ reduces to $L_2$), if there exists a computable function $f: \\Sigma_1^{*}\\mapsto\\Sigma_2^{*}$ s.t. for every $w\\in\\Sigma_1^{*}$, $w\\in L_1\\iff f(w)\\in L_2$. We sometimes use the notation $A\\leq^p_m B$ to denote that the function $f$ is polynomial time constructible.\nA decision problem is a Boolean-valued function $D:\\Sigma^{*}\\mapsto\\{0,1\\}$. We can view $D$ as a language $L_D = \\{ x\\in\\Sigma^{*} : D(x)=1\\}$. Conversely, every language $L\\subseteq\\Sigma^{*}$ can be uniquely associated with a unique decision problem $D_L$ called the membership problem. Here, $x\\in L\\iff D_L(x)=1$. A Turing machine $T$ computes/solves the decision problem $D$ if for any input $x\\in\\Sigma^{*}$, $T$ halts on any input $x$ and produces output $T(x)=D(x)$.\nRecall that complexity classes P and NP are defined w.r.t. decision problems. $L$ is in P if $\\exists$ an efficient decider for the membership problem of any string in $\\Sigma^{*}$. $L$ is in NP if there exists an efficient verifier and a polynomial sized certificate for the membership problem of any string in $\\Sigma^{*}$.\nIn complexity theory, many problems can be naturally expressed as search problems (for example, TSP, HamCycle, etc.), but are shoehorned into the above model of decision problems in order for us to easily classify them into classes like P and NP.\nSearch Problems: A search problem is a relation $R\\subset\\Sigma_{in}^{*}\\times\\Sigma_{out}^{*}$, i.e., $(x,y)\\in R$, where $x\\in\\Sigma_{in},y\\in\\Sigma_{out}$ are strings belonging to the input and output alphabets respectively. Search problems are also known as relational problems / optimization problems. A Turing machine $T$ decides/computes/solves $R$, if for any input $x\\in\\Sigma_{in}$, $T(x)$ halts and produces $y\\in\\Sigma_{out}$ s.t. $(x,y)\\in R$, or correctly states that no such $y$ exists.\n$R\\subset\\Sigma_{in}^{*}\\times\\Sigma_{out}^{*}$ is a polynomially-balanced relation if for any $(x,y)\\in R$, $|y|=\\text{poly}(|x|)$. Since the complexity class NP is defined w.r.t. decision problems, we need to introduce an equivalent notion for search problems. Informally, this is denoted by the class FNP (or Function NP). Formally, a polynomially-balanced relation $R\\in$ FNP (i.e., $R$ is an NP search problem) if $R$ is polynomial-time computable. Note that if $R$ is polynomially balanced, any $y$ s.t. $(x,y)\\in R$ serves as the certificate/witness for $x$. A search problem $R$ is in FP if $R\\in$ FNP and if there exists an efficient decider for $R$.\nFP = FNP iff P = NP.\nExamples of Search-to-Decision reductions In this section, we see some examples of search-to-decision reductions. Let us start with designing a search-to-decision reduction for SAT, which is an NP-complete problem. Recall that decision problems answer the following flavour of questions:\nGiven a problem $P$, is $x$ a solution to $P$? (Yes/No).\nOn the other hand, search problems answer the following flavour of questions:\nGiven a problem $P$, output a solution to $P$ with some property.\nFor example, given a problem $P$, output a solution to $P$ that has the minimum length. We use the satisfiability problem (SAT) as an example to further illustrate the two notions:\nDecision problem: Given a propositional formula $\\phi$, decide if $\\phi$ is satisfiable. Search problem: Given a propositional formula $\\phi$, find a satisfying assignment for $\\phi$. Note that SATSearch $\\in$ FNP but SATSearch $\\notin$ TFNP, since a formula may be unsatisfiable.\nAs we see above, if it is easy to solve the Search version of a problem $P$, it is straightforward to solve the Decision version of $P$. The more challenging question is:\nCan we efficiently solve the Search version of a problem $P$, if we know how to solve the Decision version of $P$ efficiently?\nSearch-to-Decision Reduction for SAT Formally, let $O_D^p$ be a decision oracle for a search problem $R\\subset\\Sigma_{in}^{*}\\times\\Sigma_{out}^{*}$ s.t. querying $O_D^p$ produces $\\mathbb{I}[ \\exists x\\in\\Sigma_{in};|; x \\text{ has property } p]$; i.e., querying $O_D$ with an appropriate parameter for a property $p$ outputs a yes or a no indicating if there exists any input that satisfies the property $p$ (usually taken to be some bound on the input size). Our goal now is to produce $y\\in\\Sigma_{out}$ s.t. $(x,y)\\in R$, using oracle calls to $O_D^p$.\nThere are two inputs to the SATSearchToDecision() reduction\nthe propositional formula $\\phi$ or f, and the decision oracle for SAT on $O_D$ or DSAT(f,assign) which takes as input a propositional formula f and a restricted assignment assign and returns yes iff f is satisfiable under the restriction assign. The output of the SATSearchToDecision() procedure is a satisfying assignment for $\\phi$( or f). SATSearchToDecision(f,DSAT()){ assignarr = [*,*,....,*];// Intitalize assignarr as an n-bit empty array. if(DSAT(f,assignarr)=0) // is f satisfiable without restrictions? return -1; // f is not satisfiable for (i=1;i\u003c=n; i++){ assignarr[i]= 0 //Fix the ith bit in x to be 1. // This fixes the ith literal in f. if (DSAT(f,assignarr)==1) continue; // move on to the i+1th coordinate, // with the ith bit set to 0. assignarr[i]= 1 //Fix the ith bit in x to be 0. // This fixes the ith literal in f. if (DSAT(f,assignarr)==1) continue; // move on to the i+1th coordinate, // with the ith bit set to 1. return assignarr; } Search-to-Decision Reduction for CLIQUE Earlier we saw that the property used by the decision oracle was a restricted assignment. We list another example of a search-to-decision reduction for the Clique problem (another one of Karp’s original 21 NP-complete problems), to give a flavour of a different decision oracle property - based on size.\nThe Clique Decision problem: Given a graph $G=(V,E)$, decide if $G$ contains a clique of size $\\leq k$. The Clique Search problem: Given a graph $G=(V,E)$, find a clique of size $\\leq k$ in $G$ if it exists. As seen above, there are two inputs to the CliqueSearchToDecision() reduction:\nthe graph $G$ as an adjacency list L, and the decision oracle for Clique on $O_D$ or DCLIQUE(L,k) which takes as input a adjacency list L and a parameter k and returns yes iff the graph corresponding to L contains a clique of size at most k. The output of the CliqueSearchToDecision() procedure is an adjacency list corresponding to a clique in $G$ of size $\\leq k$. Recall that an adjacency list is a collection of unordered lists used to represent a finite graph. We use the following definition of adjacency lists (this is a modification of the definition given in CLRS): An adjacency list is a singly linked list where each element in the list corresponds to a particular vertex, and each element in the list itself points to a singly linked list of the neighboring vertices of that vertex. See the diagram below.\nSATSearchToDecision(L,DCLIQUE()){ if(DCLIQUE(L,k)=0) return -1; // There is no clique of size at most k for every vertex v of G { Let Lv be the new adjacency list obtained by removing vertex v from G. // easily done using the above datastructure. if(DCLIQUE(Lv,k)=1) L = Lv; // update the graph to reflect G = G-v. } return L; } Formal notion of Self-reducibility Above we saw examples of problems admitting efficient search-to-decision reductions where both the search and decision verions are computationally hard. Maximum Matching and Shortest Path are problems where both the search and decision versions are computationally easy, and hence admit efficiently constructible search-to-decision reductions by definition. This is interesting since these two categories of problems are very different from a computational perspective.\nHowever, in the context of the existence of efficient search-to-decision reductions, not all problems are created equal. While, some problems have naturally equivalent notions of search and decision problems, for others search and decision problems may not be computationally equivalent.\nA problem is self-reducible or auto-reducibile if it admits an efficient search-to-decision reduction, i.e., any efficient solution to the decision version of the problem implies an efficient solution to the search version of the problem.\nDownward self-reducibility A search problem $R$ is downward self-reducible (d.s.r) if there is a polynomial time oracle algorithm for $R$ that on input $x \\in \\Sigma^{*}$ makes queries to an $R$-oracle of size strictly less than $|x|$. In other words, a language $L$ is d.s.r. if there exists a polynomial time algorithm $A^O$ deciding $x\\overset{?}{\\in} L$ with a membership oracle $O$ for $L$ that can handle subqueries for strings $z\\overset{?}{\\in} L$ s.t. $|z|\u003c|x|$.\nWe can extend the notion of downward self-reducibility to functions or decision problems as follows: A function $f:\\Sigma^{*}\\mapsto \\{0,1\\}$ is downward self-reducible if there exists a polynomial time algorithm $A^{O_f}$ s.t. on any input of length $n$, $A$ only makes queries of length $","wordCount":"4103","inLanguage":"en","image":"https://theoretickles.netlify.app/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2025-02-01T11:51:18+05:30","dateModified":"2025-02-01T11:51:18+05:30","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://theoretickles.netlify.app/posts/selfreductions/"},"publisher":{"@type":"Organization","name":"Theoretickles","logo":{"@type":"ImageObject","url":"https://theoretickles.netlify.app/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://theoretickles.netlify.app/ accesskey=h title="Theoretickles (Alt + H)"><img src=https://theoretickles.netlify.app/apple-touch-icon.png alt aria-label=logo height=35>Theoretickles</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://theoretickles.netlify.app/categories/ title=categories><span>categories</span></a></li><li><a href=https://theoretickles.netlify.app/tags/ title=tags><span>tags</span></a></li><li><a href=https://chatsagnik.github.io title=chatsagnik><span>chatsagnik</span>&nbsp;
<svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://theoretickles.netlify.app/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li><li><a href=https://theoretickles.netlify.app/archives/ title=archives><span>archives</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://theoretickles.netlify.app/>Home</a>&nbsp;»&nbsp;<a href=https://theoretickles.netlify.app/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Self-Reducibility</h1><div class=post-meta><span title='2025-02-01 11:51:18 +0530 IST'>February 1, 2025</span>&nbsp;·&nbsp;20 min&nbsp;·&nbsp;4103 words&nbsp;·&nbsp;Me&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/posts/selfreductions.md rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#introduction aria-label=Introduction>Introduction</a></li><li><a href=#search-to-decision-reductions aria-label="Search-to-Decision Reductions">Search-to-Decision Reductions</a><ul><li><a href=#examples-of-search-to-decision-reductions aria-label="Examples of Search-to-Decision reductions">Examples of Search-to-Decision reductions</a><ul><li><a href=#search-to-decision-reduction-for-sat aria-label="Search-to-Decision Reduction for SAT">Search-to-Decision Reduction for SAT</a></li><li><a href=#search-to-decision-reduction-for-clique aria-label="Search-to-Decision Reduction for CLIQUE">Search-to-Decision Reduction for CLIQUE</a></li></ul></li></ul></li><li><a href=#formal-notion-of-self-reducibility aria-label="Formal notion of Self-reducibility">Formal notion of Self-reducibility</a><ul><li><a href=#downward-self-reducibility aria-label="Downward self-reducibility">Downward self-reducibility</a><ul><li><a href=#an-application-of-downward-self-reductions-mahaneys-theorem aria-label="An application of Downward Self-Reductions: Mahaney&rsquo;s Theorem">An application of Downward Self-Reductions: Mahaney&rsquo;s Theorem</a></li></ul></li></ul></li><li><a href=#which-problems-are-not-known-to-be-self-reducible aria-label="Which problems are (not) known to be self-reducible?">Which problems are (not) known to be self-reducible?</a><ul><li><a href=#taxonomy-of-np-search-problems aria-label="Taxonomy of NP search problems">Taxonomy of NP search problems</a><ul><li><a href=#important-subclasses-of-tfnp aria-label="Important subclasses of TFNP">Important subclasses of TFNP</a></li></ul></li><li><a href=#complexity-of-self-reducibile-problems aria-label="Complexity of self-reducibile problems">Complexity of self-reducibile problems</a></li></ul></li><li><a href=#footnotes aria-label=Footnotes>Footnotes</a></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><blockquote><p><em>This post assumes basic familiarity with Turing machines, P, NP, NP-completeness, decidability, and undecidability. The reader is referred to the book by Sipser, or the book by Arora and Barak for any formal definitions that have been skipped in this post. Without further ado, let&rsquo;s dive in.</em></p></blockquote><hr><h1 id=introduction>Introduction<a hidden class=anchor aria-hidden=true href=#introduction>#</a></h1><p>In an earlier post, we familiarised ourselves with the <a href=https://theoretickles.netlify.app/posts/reductions rel=noopener class=external-link target=_blank>notion of reductions</a>. Towards the end, we introduced the notion of <strong>self-reducibility</strong> which is our main topic of focus today. We start by familiarising ourselves with a few concepts.</p><h1 id=search-to-decision-reductions>Search-to-Decision Reductions<a hidden class=anchor aria-hidden=true href=#search-to-decision-reductions>#</a></h1><p>In the world of complexity and computability, a <em>language</em> is a set of strings formed out of some alphabet. Formally, $L\subseteq\Sigma^{*}$, where the alphabet $\Sigma$ is a finite set of symbols, and $\Sigma^{*}$ refers to the <a href=https://en.wikipedia.org/wiki/Kleene_star#Definition rel=noopener class=external-link target=_blank>Kleene closure</a> of $\Sigma$.</p><p><a href=https://theoretickles.netlify.app/posts/reductions rel=noopener class=external-link target=_blank>Last time we formalized reductions in terms of Turing Machines</a>. We now explicitly define mapping reductions (equivalent to Karp reductions for TMs) in terms of languages. Let $L_1 \subseteq \Sigma_1^{*}$ and $L_2 \subseteq \Sigma_2^{*}$ be languages. Recall that $L_1\leq_m L_2$ (or, $L_1$ reduces to $L_2$), if there exists a computable function $f: \Sigma_1^{*}\mapsto\Sigma_2^{*}$ s.t. for every $w\in\Sigma_1^{*}$, $w\in L_1\iff f(w)\in L_2$. We sometimes use the notation $A\leq^p_m B$ to denote that the function $f$ is polynomial time constructible.</p><p>A <strong>decision problem</strong> is a Boolean-valued function $D:\Sigma^{*}\mapsto\{0,1\}$. We can view $D$ as a language $L_D = \{ x\in\Sigma^{*} : D(x)=1\}$. Conversely, every language $L\subseteq\Sigma^{*}$ can be uniquely associated with a unique decision problem $D_L$ called the <strong>membership problem</strong>. Here, $x\in L\iff D_L(x)=1$. A Turing machine $T$ computes/solves the decision problem $D$ if for any input $x\in\Sigma^{*}$, $T$ halts on any input $x$ and produces output $T(x)=D(x)$.</p><p>Recall that complexity classes <strong>P</strong> and <strong>NP</strong> are defined w.r.t. decision problems. $L$ is in <strong>P</strong> if $\exists$ an efficient decider for the membership problem of any string in $\Sigma^{*}$. $L$ is in <strong>NP</strong> if there exists an efficient verifier and a polynomial sized certificate for the membership problem of any string in $\Sigma^{*}$.</p><p>In complexity theory, many problems can be naturally expressed as <strong>search problems</strong> (for example, TSP, HamCycle, etc.), but are shoehorned into the above model of <strong>decision problems</strong> in order for us to easily classify them into classes like <strong>P</strong> and <strong>NP</strong>.</p><ul><li><strong>Search Problems:</strong> A search problem is a relation $R\subset\Sigma_{in}^{*}\times\Sigma_{out}^{*}$, i.e., $(x,y)\in R$, where $x\in\Sigma_{in},y\in\Sigma_{out}$ are strings belonging to the input and output alphabets respectively. Search problems are also known as relational problems / optimization problems.</li></ul><p>A Turing machine $T$ decides/computes/solves $R$, if for any input $x\in\Sigma_{in}$, $T(x)$ halts and produces $y\in\Sigma_{out}$ s.t. $(x,y)\in R$, or correctly states that no such $y$ exists.</p><ul><li>$R\subset\Sigma_{in}^{*}\times\Sigma_{out}^{*}$ is a <strong>polynomially-balanced relation</strong> if for any $(x,y)\in R$, $|y|=\text{poly}(|x|)$.</li></ul><p>Since the complexity class <strong>NP</strong> is defined w.r.t. decision problems, we need to introduce an equivalent notion for search problems. Informally, this is denoted by the class <strong>FNP</strong> (or Function <strong>NP</strong>). Formally, a polynomially-balanced relation $R\in$ <strong>FNP</strong> (i.e., $R$ is an NP search problem) if $R$ is polynomial-time computable. Note that if $R$ is polynomially balanced, any $y$ s.t. $(x,y)\in R$ serves as the certificate/witness for $x$. A search problem $R$ is in <strong>FP</strong> if $R\in$ <strong>FNP</strong> and if there exists an efficient decider for $R$.</p><blockquote><p><strong>FP</strong> = <strong>FNP</strong> iff <strong>P</strong> = <strong>NP</strong>.</p></blockquote><h2 id=examples-of-search-to-decision-reductions>Examples of Search-to-Decision reductions<a hidden class=anchor aria-hidden=true href=#examples-of-search-to-decision-reductions>#</a></h2><p>In this section, we see some examples of search-to-decision reductions. Let us start with designing a search-to-decision reduction for SAT, which is an <strong>NP-complete</strong> problem. Recall that decision problems answer the following flavour of questions:</p><blockquote><p>Given a problem $P$, is $x$ a solution to $P$? (Yes/No).</p></blockquote><p>On the other hand, search problems answer the following flavour of questions:</p><blockquote><p>Given a problem $P$, output a solution to $P$ with some property.</p></blockquote><p>For example, given a problem $P$, output a solution to $P$ that has the minimum length. We use the satisfiability problem (SAT) as an example to further illustrate the two notions:</p><ul><li><strong>Decision problem:</strong> Given a propositional formula $\phi$, decide if $\phi$ is satisfiable.</li><li><strong>Search problem:</strong> Given a propositional formula $\phi$, find a satisfying assignment for $\phi$.</li></ul><p>Note that SATSearch $\in$ <strong>FNP</strong> but SATSearch $\notin$ <strong>TFNP</strong>, since a formula may be unsatisfiable.</p><p>As we see above, if it is easy to solve the Search version of a problem $P$, it is straightforward to solve the Decision version of $P$. The more challenging question is:</p><blockquote><p>Can we efficiently solve the Search version of a problem $P$, if we know how to solve the Decision version of $P$ efficiently?</p></blockquote><h3 id=search-to-decision-reduction-for-sat>Search-to-Decision Reduction for SAT<a hidden class=anchor aria-hidden=true href=#search-to-decision-reduction-for-sat>#</a></h3><p>Formally, let $O_D^p$ be a decision oracle for a search problem $R\subset\Sigma_{in}^{*}\times\Sigma_{out}^{*}$ s.t. querying $O_D^p$ produces $\mathbb{I}[ \exists x\in\Sigma_{in};|; x \text{ has property } p]$; i.e., querying $O_D$ with an appropriate parameter for a <em>property</em> $p$ outputs a yes or a no indicating if there exists any input that satisfies the property $p$ (usually taken to be some bound on the input size). Our goal now is to produce $y\in\Sigma_{out}$ s.t. $(x,y)\in R$, using oracle calls to $O_D^p$.</p><p>There are two inputs to the <code>SATSearchToDecision()</code> reduction</p><ul><li>the propositional formula $\phi$ or <code>f</code>, and</li><li>the decision oracle for SAT on $O_D$ or <code>DSAT(f,assign)</code> which takes as input a propositional formula <code>f</code> and a restricted assignment <code>assign</code> and returns yes iff <code>f</code> is satisfiable under the restriction <code>assign</code>. The output of the <code>SATSearchToDecision()</code> procedure is a satisfying assignment for $\phi$( or <code>f</code>).</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-C data-lang=C><span class=line><span class=cl><span class=nf>SATSearchToDecision</span><span class=p>(</span><span class=n>f</span><span class=p>,</span><span class=nf>DSAT</span><span class=p>()){</span>
</span></span><span class=line><span class=cl>    <span class=n>assignarr</span> <span class=o>=</span> <span class=p>[</span><span class=o>*</span><span class=p>,</span><span class=o>*</span><span class=p>,....,</span><span class=o>*</span><span class=p>];</span><span class=c1>// Intitalize assignarr as an n-bit empty array.
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>if</span><span class=p>(</span><span class=nf>DSAT</span><span class=p>(</span><span class=n>f</span><span class=p>,</span><span class=n>assignarr</span><span class=p>)</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span> <span class=c1>// is f satisfiable without restrictions?
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span> <span class=c1>// f is not satisfiable
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>for</span> <span class=p>(</span><span class=n>i</span><span class=o>=</span><span class=mi>1</span><span class=p>;</span><span class=n>i</span><span class=o>&lt;=</span><span class=n>n</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=n>assignarr</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=c1>//Fix the ith bit in x to be 1.
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=c1>// This fixes the ith literal in f.
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=k>if</span> <span class=p>(</span><span class=nf>DSAT</span><span class=p>(</span><span class=n>f</span><span class=p>,</span><span class=n>assignarr</span><span class=p>)</span><span class=o>==</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>continue</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=c1>// move on to the i+1th coordinate,
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=c1>// with the ith bit set to 0.
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=n>assignarr</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>        <span class=c1>//Fix the ith bit in x to be 0.
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=c1>// This fixes the ith literal in f.
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=k>if</span> <span class=p>(</span><span class=nf>DSAT</span><span class=p>(</span><span class=n>f</span><span class=p>,</span><span class=n>assignarr</span><span class=p>)</span><span class=o>==</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>continue</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=c1>// move on to the i+1th coordinate,
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=c1>// with the ith bit set to 1.
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>return</span> <span class=n>assignarr</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h3 id=search-to-decision-reduction-for-clique>Search-to-Decision Reduction for CLIQUE<a hidden class=anchor aria-hidden=true href=#search-to-decision-reduction-for-clique>#</a></h3><p>Earlier we saw that the property used by the decision oracle was a restricted assignment. We list another example of a search-to-decision reduction for the Clique problem (another one of Karp&rsquo;s original 21 <strong>NP-complete</strong> problems), to give a flavour of a different decision oracle property - based on size.</p><ul><li><strong>The Clique Decision problem:</strong> Given a graph $G=(V,E)$, decide if $G$ contains a clique of size $\leq k$.</li><li><strong>The Clique Search problem:</strong> Given a graph $G=(V,E)$, find a clique of size $\leq k$ in $G$ if it exists.</li></ul><p>As seen above, there are two inputs to the <code>CliqueSearchToDecision()</code> reduction:</p><ul><li>the graph $G$ as an adjacency list <code>L</code>, and</li><li>the decision oracle for Clique on $O_D$ or <code>DCLIQUE(L,k)</code> which takes as input a adjacency list <code>L</code> and a parameter <code>k</code> and returns yes iff the graph corresponding to <code>L</code> contains a clique of size at most <code>k</code>. The output of the <code>CliqueSearchToDecision()</code> procedure is an adjacency list corresponding to a clique in $G$ of size $\leq k$.</li></ul><blockquote><p>Recall that an adjacency list is a collection of unordered lists used to represent a finite graph. We use the following definition of adjacency lists (this is a modification of the definition given in CLRS): An adjacency list is a singly linked list where each element in the list corresponds to a particular vertex, and each element in the list itself points to a singly linked list of the neighboring vertices of that vertex. See the diagram below.</p></blockquote><p><img alt="Adjacency List" loading=lazy src=/posts/adjacency_list.png></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-C data-lang=C><span class=line><span class=cl><span class=nf>SATSearchToDecision</span><span class=p>(</span><span class=n>L</span><span class=p>,</span><span class=nf>DCLIQUE</span><span class=p>()){</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span><span class=p>(</span><span class=nf>DCLIQUE</span><span class=p>(</span><span class=n>L</span><span class=p>,</span><span class=n>k</span><span class=p>)</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span> <span class=c1>// There is no clique of size at most k
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>for</span> <span class=n>every</span> <span class=n>vertex</span> <span class=n>v</span> <span class=n>of</span> <span class=n>G</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>Let</span> <span class=n>Lv</span> <span class=n>be</span> <span class=n>the</span> <span class=n>new</span> <span class=n>adjacency</span> <span class=n>list</span>
</span></span><span class=line><span class=cl>        <span class=n>obtained</span> <span class=n>by</span> <span class=n>removing</span> <span class=n>vertex</span> <span class=n>v</span> <span class=n>from</span> <span class=n>G</span><span class=p>.</span>
</span></span><span class=line><span class=cl>        <span class=c1>// easily done using the above datastructure.
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=k>if</span><span class=p>(</span><span class=nf>DCLIQUE</span><span class=p>(</span><span class=n>Lv</span><span class=p>,</span><span class=n>k</span><span class=p>)</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>L</span> <span class=o>=</span> <span class=n>Lv</span><span class=p>;</span> <span class=c1>// update the graph to reflect G = G-v.
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>L</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><hr><h1 id=formal-notion-of-self-reducibility>Formal notion of Self-reducibility<a hidden class=anchor aria-hidden=true href=#formal-notion-of-self-reducibility>#</a></h1><p>Above we saw examples of problems admitting efficient search-to-decision reductions where both the search and decision verions are computationally hard. <code>Maximum Matching</code> and <code>Shortest Path</code> are problems where both the search and decision versions are computationally easy, and hence admit efficiently constructible search-to-decision reductions by definition. This is interesting since these two categories of problems are very different from a computational perspective.</p><p>However, in the context of the existence of efficient search-to-decision reductions, not all problems are created equal. While, some problems have naturally equivalent notions of search and decision problems, for others search and decision problems may not be computationally equivalent.</p><p>A problem is <strong>self-reducible</strong> or <strong>auto-reducibile</strong> if it admits an efficient search-to-decision reduction, i.e., any efficient solution to the decision version of the problem implies an efficient solution to the search version of the problem.</p><h2 id=downward-self-reducibility>Downward self-reducibility<a hidden class=anchor aria-hidden=true href=#downward-self-reducibility>#</a></h2><p>A search problem $R$ is <strong>downward self-reducible</strong> (d.s.r) if there is a polynomial time oracle algorithm for $R$ that on input $x \in \Sigma^{*}$ makes queries to an $R$-oracle of size strictly less than $|x|$. In other words, a language $L$ is d.s.r. if there exists a polynomial time algorithm $A^O$ deciding $x\overset{?}{\in} L$ with a membership oracle $O$ for $L$ that can handle subqueries for strings $z\overset{?}{\in} L$ s.t. $|z|&lt;|x|$.</p><p>We can extend the notion of downward self-reducibility to <em>functions</em> or decision problems as follows: A function $f:\Sigma^{*}\mapsto \{0,1\}$ is downward self-reducible if there exists a polynomial time algorithm $A^{O_f}$ s.t. on any input of length $n$, $A$ only makes queries of length $&lt;n$ to the membership oracle ${O_f}$, and for every input $x$, $A^{O_f}(x)=f(x)$.</p><p>It is easy to see that SAT is d.s.r. since given any formula $\phi$ on $n$-variables, one can consider only querying on restrictions of $\phi$ to figure out if $\phi$ is satisfiable.</p><blockquote><p>All <strong>NP-complete</strong> decision problems are downward self-reducible.</p></blockquote><p>This is straightforward to show using the fact that there exists a Karp-reduction from SAT to $L$ for any <strong>NP-complete</strong> problem $L$.</p><blockquote><p>Every downward self-reducible decision problem is in <strong>PSPACE</strong>.</p></blockquote><p><em>Proof.</em> Let the input to a d.s.r. problem $f$ be $x$. Then any algorithm $A$ that solves $f$ will make queries to some oracle and recursively compute the answer to each query. The depth of the recursion is at most |x|, and at each level of recursion, the algorithm needs to remember the state which requires space at most poly(|x|). This last point holds because the basic computation runs in polynomial time, and hence polynomial space.</p><p><strong>Note:</strong> We also recall that <strong>PSPACE</strong> is closed <sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> under Karp-reductions. Since, all d.s.r. languages belong to <strong>PSPACE</strong>, we can conclude that <strong>PSPACE</strong> is <strong>hard</strong> (worst-case or average-case) iff a d.s.r. language is <strong>hard</strong> (in the same sense.)</p><h3 id=an-application-of-downward-self-reductions-mahaneys-theorem>An application of Downward Self-Reductions: Mahaney&rsquo;s Theorem<a hidden class=anchor aria-hidden=true href=#an-application-of-downward-self-reductions-mahaneys-theorem>#</a></h3><p>A language $L$ is (polynomially) <strong>sparse</strong> if it the number of strings of length $n$ in $L$ is bounded by a polynomial in $n$.</p><blockquote><p><strong>[Mahaney&rsquo;s Theorem]</strong> Assuming <strong>P</strong> $\neq$ <strong>NP</strong>, there are no sparse <strong>NP-complete</strong> languages.</p></blockquote><p><em>Proof Sketch:</em> Recall the d.s.r tree of SAT. Given a SAT formula $\phi[x_1,\ldots,x_n]$ at the first level we can restrict the formula to $\phi_0[0,\ldots,x_n]$ and $\phi_1[1,\ldots,x_n]$. If $\phi$ is satisfiable, then at least one of $\phi_0$ or $\phi_1$ is satisfiable. Hence, at the $\ell$th level, at least one of the $2^{\ell}$ formulas have to be satisfiable for the original formula to be satisifable. If $L$ is a sparse NP-complete language, we have $SAT\leq^p_m L$. Hence, using a mapping reduction from SAT to $L$, we can prune the d.s.r. tree s.t. at the $\ell$th level to only contend with $\text{poly}(\ell)$ formulas. This straightforwarly yields a polynomial time SAT algorithm, since there are only $n$ levels. This violates the <a href=https://en.wikipedia.org/wiki/Exponential_time_hypothesis rel=noopener class=external-link target=_blank>Exponential Time Hypothesis</a>, and therefore there does not exist any $L$ that is both sparse and NP-complete.</p><p>The above proof sketch is due to Joshua Grochow<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>, who credits Manindra Agrawal for the original idea. See <a href=https://www.wisdom.weizmann.ac.il/~oded/MC/208.html rel=noopener class=external-link target=_blank>Oded Goldreich&rsquo;s comments here</a>. Due to the lack of formatting in the above linked blog (and for my own archival purposes), I reproduce his comments <em>as-is</em> below.</p><blockquote><p><strong>Oded&rsquo;s comments:</strong>
The proof is indeed simple, not any harder than the proof that assumes that the sparse set is a subset of a set in P (see Exercise 3.12 in my computational complexity book).</p><p>The first idea is to scan the downwards self-reducibility tree of SAT and extend at most polynomially many viable vertices at each level of the tree, where this polynomial is determined by the polynomials of the sparseness bound and the stretch of the Karp-reduction (of SAT to the sparse set). The crucial idea is the following: Rather than testing the the residual formulae at the current level by applying the Karp-reduction to each of them, one applies the Karp-reduction to the disjunction of the first formula (i.e., $\phi_1$) and each of the remaining formulae (i.e, the $\phi_i$&rsquo;s for $i>1$).</p><p>The point is that if all reduction values are distinct, then one of these values is not in the sparse set, and it follows that the first formula is not in SAT, and so the first formula can be discarded. Otherewise, if the reduction maps $\phi_1\vee\phi_i$ and $\phi_1\vee\phi_i$ to the same value, then we can discard (say) $\phi_i$, since either $\phi_1$ is in SAT (and remains viable) or $\phi_1$ is not in SAT and so $\phi_i$ and $\phi_j$ have the same SAT-value (and so it suffices to keep either of them).</p></blockquote><hr><h1 id=which-problems-are-not-known-to-be-self-reducible>Which problems are (not) known to be self-reducible?<a hidden class=anchor aria-hidden=true href=#which-problems-are-not-known-to-be-self-reducible>#</a></h1><p>Recall that self-reducibility is precluded in cases where the decision version is easy and while the search version is hard. For example, consider the <code>Factoring</code> problem:</p><ul><li><strong>The Factoring Decision problem:</strong> Given a natural number $n$, decide if $n$ is prime.</li><li><strong>The Factoring Search problem:</strong> Given (the binary representation of) a natural number $n$, produce all of its factors.</li></ul><p>Many important classes of cryptosystems such as <a href=https://en.wikipedia.org/wiki/RSA_cryptosystem rel=noopener class=external-link target=_blank>RSA</a> <sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup> are based on the hardness of the <code>Factoring Search problem</code>.<sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup> On the other hand, the <code>Factoring Decision problem</code> (also known as the <code>Primality testing problem</code>) has long been known to computationally tractable.<sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup> Hence, <code>Factoring</code> does not appear to be straightforwardly self-reducible.</p><p>This leans into the conjecture that not every problem in <strong>NP</strong> is necessarily self-reducible (for example, Factoring). Bellare and Goldwasser'94 formally proved that if <strong>EE</strong> $\neq$ <strong>NEE</strong>, then there exists a language in <strong>NP</strong> that is not self-reducible.<sup id=fnref:6><a href=#fn:6 class=footnote-ref role=doc-noteref>6</a></sup></p><p>Following the above result, Beame et al. (1998)<sup id=fnref:7><a href=#fn:7 class=footnote-ref role=doc-noteref>7</a></sup> showed the existence of various search problems in <strong>FNP</strong> that are not computationally equivalent to their decision versions. This is particularly important when a solution for the search problem is <strong>guaranteed to exist</strong> (but hard to find).</p><p>One of the research directions on the notion of self-reducible problems is to characterise their complexity. Even though decisional complexity is well understood at an undergraduate level, the complexity of search problems is strictly a graduate level topic due to the sheer amount of prerequisites involved. In the remainder of this post, I will attempt to provide an introduction to the complexity landscape of <strong>NP</strong>-search problems and state a few connected results related to self-reducibility.</p><h2 id=taxonomy-of-np-search-problems>Taxonomy of NP search problems<a hidden class=anchor aria-hidden=true href=#taxonomy-of-np-search-problems>#</a></h2><p>The complexity class <strong>TFNP</strong> consists of all search problems in <strong>FNP</strong> that are total in the sense that a solution is guaranteed to exist. In other words, $R\in$<strong>TFNP</strong>$\iff R\in$<strong>FNP</strong> and $R$ is total, i.e., $\forall x\in\Sigma_{in}, \exists y\in\Sigma_{out}$ s.t. $(x,y)\in R$. Using the totality of <strong>TFNP</strong>, it is straightforward to show that <strong>TFNP</strong> $=$ <strong>FNP</strong> $\cap$ <strong>coFNP</strong>.</p><p>In the case of decision problems, the notion of <strong>NP-completeness</strong> plays a huge role in establishing relative hardness results among many problems of interests, and has a beautiful relationship with the concept of reductions.</p><blockquote><p>There is an <strong>FNP-complete</strong> problem in <strong>TFNP</strong> if <strong>NP</strong> = <strong>coNP</strong>.</p></blockquote><p>Since we consider a <strong>P</strong> $\neq$ <strong>NP</strong> to be a reasonable assumption, it is very likely that <strong>NP</strong> $\neq$ <strong>coNP</strong>. Does this imply that there is no notion of a <em>hard</em> search problem? That also seems unlikely, because common sense dictates that search versions of problems in <strong>NP</strong> would be in some sense reducible to search versions of <strong>NP-complete</strong> problems!</p><p>How do we then characterize the hardness of efficiently verifiable search problems? In other words, can we formally provide examples of search problems that are (for some notion of hardness) the hardest in <strong>TFNP</strong>? At this point, we list some interesting candidate computational problems known to be in <strong>TFNP</strong> that are not known to have polynomial time algorithms:</p><ul><li><code>NASHx</code>: Finding a mixed Nash equilibrium of a game with $x$ players.</li><li><code>Brouwer</code>/<code>Kakutani</code>: Finding Brouwer/Kakutani fixed points for continuous functions.<sup id=fnref:8><a href=#fn:8 class=footnote-ref role=doc-noteref>8</a></sup><sup id=fnref:9><a href=#fn:9 class=footnote-ref role=doc-noteref>9</a></sup></li><li><code>Factoring</code>: Finding a (or all) prime factors of a number $n\geq 2$.</li><li><code>SetCover</code>: Finding a minimum Set Cover.</li></ul><p>Unfortunately, it is believed that <strong>TFNP</strong> has <a href=https://theoretickles.netlify.app/posts/reductions/#completeness rel=noopener class=external-link target=_blank>no complete problems</a> since it is a <strong>semantic class</strong>!<sup id=fnref:10><a href=#fn:10 class=footnote-ref role=doc-noteref>10</a></sup></p><p>Hence, in order to characterize the notion of hardness in search problems, various syntactic subclasses have been defined in an attempt to classify the many diverse problems that belong to <strong>TFNP</strong>.</p><p>Recall that TFNP problems have the following two characteristics - <strong>(a)</strong> any solution can be checked efficiently <em>(the NP property)</em>, and <strong>(b)</strong> there always exists at least one solution <em>(the totality property)</em>. The syntactic subclasses are defined based on the combinatorial principle used to argue totality in <strong>TFNP</strong>. In other words, each subclass of <strong>TFNP</strong> has a corresponding existence proof principle (for example, an instance of a circuit or graph), <em>one that when applied in a general context, does not yield a polynomial-time algorithm</em>.</p><h3 id=important-subclasses-of-tfnp>Important subclasses of TFNP<a hidden class=anchor aria-hidden=true href=#important-subclasses-of-tfnp>#</a></h3><p>We define two important subclasses of TFNP in this post - <strong>PLS</strong> and <strong>PPAD</strong> (along with a whole host of others in the footnotes section).</p><p>The complexity class <strong>PLS</strong> (also known as <strong>Polynomial Local Search</strong>), is a subclass of TFNP function problems which contains problems that are guaranteed to have a solution because of the lemma that &ldquo;every finite directed acyclic graph has a sink.&rdquo;</p><blockquote><p><em>Remark:</em> The graph instance above may be exponentially large. For a finer intuition see the description of <strong>EOL</strong><sup id=fnref:11><a href=#fn:11 class=footnote-ref role=doc-noteref>11</a></sup> in the footnotes.</p></blockquote><p><strong>PLS</strong> captures problems of finding a local minimum of an objective function $f$, in contexts where any candidate solution $x$ has a local neighbourhood within which we can readily check for the existence of some other point having a lower value of $f$. One of the motivations behind defining <strong>PLS</strong> was to capture the notion of problems with existing local optimum in <strong>NP-hard problems</strong> like <code>TSP</code>. Since a <strong>PLS</strong> problem always has a local optimum, it therefore always a solution (as the set of solutions is finite). Hence, using the above definitions, we have:</p><blockquote><p><strong>FP</strong> $\subseteq$ <strong>PLS</strong> $\subseteq$ <strong>TFNP</strong> $\subseteq$ <strong>FNP</strong>.<sup id=fnref:12><a href=#fn:12 class=footnote-ref role=doc-noteref>12</a></sup></p></blockquote><p>Examples of <strong>PLS-complete problems</strong> include search versions of <code>Set-Cover</code>, <code>Metric-TSP</code>, and <code>Weighted Independent-Set</code> (among many many others).</p><p>Another subclass of <strong>TFNP</strong> is the complexity class <strong>PPAD</strong>. <strong>PPAD</strong> is defined as the set of functions in <strong>TFNP</strong> that reduce in polynomial time to the <code>End-Of-Line (EOL)</code> problem.<sup id=fnref1:11><a href=#fn:11 class=footnote-ref role=doc-noteref>11</a></sup> In other words, a problem is complete for <strong>PPAD</strong> if it belongs to <strong>PPAD</strong> and if <strong>EOL</strong> reduces in polynomial time to that problem. <strong>PPAD</strong> is contained in <strong>PPA</strong> $\cap$ <strong>PPP</strong> <sup id=fnref:13><a href=#fn:13 class=footnote-ref role=doc-noteref>13</a></sup><sup id=fnref:14><a href=#fn:14 class=footnote-ref role=doc-noteref>14</a></sup> and could be regarded as the directed version of the class <strong>PPA</strong>.<sup id=fnref1:13><a href=#fn:13 class=footnote-ref role=doc-noteref>13</a></sup></p><p><code>NASH2</code> $\in$ <strong>PPAD</strong>, and <code>NASH3</code> is <strong>PPAD-complete</strong>. The <code>Brouwer</code> and <code>Kakutani</code> problems are also in <strong>PPAD</strong>.</p><p>Problems in <strong>PLS</strong> can be solved with local improvement algorithms, while problems in <strong>PPAD</strong> admit &ldquo;optimality equations&rdquo; that characterize solutions as fixed points.</p><blockquote><p>PPAD and PLS are believed to be strictly incomparable.<sup id=fnref1:7><a href=#fn:7 class=footnote-ref role=doc-noteref>7</a></sup><sup id=fnref:15><a href=#fn:15 class=footnote-ref role=doc-noteref>15</a></sup></p></blockquote><p>The complexity class Continuous Local Search <strong>CLS</strong> = <strong>PPAD</strong> $\cap$ <strong>PLS</strong>.<sup id=fnref:16><a href=#fn:16 class=footnote-ref role=doc-noteref>16</a></sup><sup id=fnref:17><a href=#fn:17 class=footnote-ref role=doc-noteref>17</a></sup><sup id=fnref2:11><a href=#fn:11 class=footnote-ref role=doc-noteref>11</a></sup> <code>Gradient Descent</code> is in <strong>CLS</strong>.</p><p>The following diagram (<a href="https://www.youtube.com/watch?v=as720_SRpY0" rel=noopener class=external-link target=_blank>appropriated from this talk</a>) captures the above discussion in a nutshell.</p><p><img alt="TFNP problem landscape" loading=lazy src=/posts/TFNP.jpg></p><h2 id=complexity-of-self-reducibile-problems>Complexity of self-reducibile problems<a hidden class=anchor aria-hidden=true href=#complexity-of-self-reducibile-problems>#</a></h2><p>Earlier we saw that every downward self-reducible decision problem is in <strong>PSPACE</strong>. The following result was recently shown, as an analogue for search problems.</p><blockquote><p>Every downward self-reducible search problem in TFNP is in PLS. <sup id=fnref:18><a href=#fn:18 class=footnote-ref role=doc-noteref>18</a></sup></p></blockquote><p>Hence <strong>PLS</strong> is in some senses the functional analogue of <strong>PSPACE</strong>. Harsha et al. (2023) <sup id=fnref1:18><a href=#fn:18 class=footnote-ref role=doc-noteref>18</a></sup> also show that most natural <strong>PLS-complete</strong> problems are downward self-reducible. We end with an important open question by Harsha et al. (2023) <sup id=fnref2:18><a href=#fn:18 class=footnote-ref role=doc-noteref>18</a></sup>:</p><blockquote><p>Is Factoring downward self reducible?</p></blockquote><p>If Factoring is downward self-reducible, then Factoring$\in$<strong>UEOPL</strong>$\subseteq$<strong>PPAD</strong>$\cap$<strong>PLS</strong> <sup id=fnref3:18><a href=#fn:18 class=footnote-ref role=doc-noteref>18</a></sup>. The complexity class <strong>UniqueEOPL</strong> (Unique End of Potential Line) captures search problems with the property that their solution space forms an <em>exponentially</em> large line with increasing cost.<sup id=fnref:19><a href=#fn:19 class=footnote-ref role=doc-noteref>19</a></sup><sup id=fnref:20><a href=#fn:20 class=footnote-ref role=doc-noteref>20</a></sup> From one candidate solution we can calculate another candidate solution in polynomial time. The end of that line is the (unique) solution of the search problem. This implies that no efficient factoring algorithm exists using the factorization of smaller numbers.</p><hr><h1 id=footnotes>Footnotes<a hidden class=anchor aria-hidden=true href=#footnotes>#</a></h1><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>We recall the notion of <a href=https://theoretickles.netlify.app/posts/reductions#completeness rel=noopener class=external-link target=_blank>notion of complete problems</a> here.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p><a href=https://arxiv.org/pdf/1610.05825 rel=noopener class=external-link target=_blank>See this preprint</a>.&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p><strong>The RSA problem:</strong> Find $M$ given the public key $(n,e)$ and a cipher text $C\equiv M^e\mod n$.&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4><p>If we can solve the factoring problem then we can solve the RSA problem by factoring the modulus n. Hence, Factoring $\implies$ RSA.&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5><p>The seminal result of Agarwal, Kayal, and Saxena showed that this problem is in <strong>P</strong>. See <a href=https://www.tcs.tifr.res.in/~jaikumar/Papers/AKS-revised.pdf rel=noopener class=external-link target=_blank>this writeup</a> for more details on the result.&#160;<a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:6><p><strong>EE</strong> equals DTIME($2^{2^{O(n)}}$).&#160;<a href=#fnref:6 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:7><p>Paul Beame, Stephen Cook, Jeff Edmonds, Russell Impagliazzo, and Toniann
Pitassi. 1998. The Relative Complexity of NP Search Problems. J. Comput. System
Sci. 57, 1 (1998), 3–19. <a href=https://doi.org/10.1145/225058.225147 rel=noopener class=external-link target=_blank>https://doi.org/10.1145/225058.225147</a>&#160;<a href=#fnref:7 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref1:7 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:8><p><strong>Brouwer&rsquo;s fixed-point theorem</strong> states that for any continuous function $f$ mapping a nonempty compact convex set to itself, there is a point $x_0$ such that $f(x_0)=x_0$.&#160;<a href=#fnref:8 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:9><p>The <strong>Kakutani fixed point theorem</strong> is a generalization of the Brouwer fixed point theorem to set-valued functions. By <a href=https://en.wikipedia.org/wiki/Weller%27s_theorem rel=noopener class=external-link target=_blank>Weller&rsquo;s Theorem</a>, Kakutani&rsquo;s fixed-point theorem is used in proving the existence of cake allocations that are both envy-free and Pareto efficient.&#160;<a href=#fnref:9 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:10><p>A complexity class is called a <strong>semantic class</strong> if the Turing Machine (TM) defining this class has a property that is undecidable. See <a href=https://www.karlin.mff.cuni.cz/~krajicek/papadim1.pdf rel=noopener class=external-link target=_blank>Papadimitrou&rsquo;s original paper</a> and <a href=https://cstheory.stackexchange.com/questions/1233/semantic-vs-syntactic-complexity-classes rel=noopener class=external-link target=_blank>this Stackexchange link</a> for a more formal discussion on this topic. In a nutshell, promise classes such as <strong>RP</strong>, <strong>ZPP</strong>, <strong>BPP</strong> are semantic.&#160;<a href=#fnref:10 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:11><p><strong>EOL</strong> is the class of problems which can be reduced to the <code>EOL</code> problem instance: Given a exponentially large directed graph consisting of lines and cycles on the vertex set $[2^𝑛]$, find any sink of the graph assuming vertex 1 is the source and every vertex has in and out degree at most 1. Note that we overload the notation <strong>EOL</strong> to refer to both the problem and the complexity class.&#160;<a href=#fnref:11 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref1:11 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref2:11 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:12><p>From our discussions above, it may be unclear why search problems in <strong>FP</strong> have to be <em>total</em>. To see why, consider $R\in$ <strong>FP</strong> and fix a special string $y_0$ s.t. $\forall x\in\Sigma_{in}^{*}$ s.t. $(x,y_0)\notin R$. An easy way to construct $y_0$ is to append every $y\in\Sigma_{out}^{*}$ with a $1$, and set $y_0$ as the all zero string.&#160;<a href=#fnref:12 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:13><p>The <strong>Complexity class PPA</strong> (also known as <strong>Polynomial Parity Argument</strong>) captures computational search problems whose totality is rooted in the handshaking lemma for undirected graphs: &ldquo;all graphs of maximum degree 2 have an even number of leaves.&rdquo;
More precisely, <strong>PPA</strong> captures search problems for which there is a polynomial-time algorithm that, given any string, computes its &rsquo;neighbor&rsquo; strings (of which there are at most two). Then given a leaf string (i.e. one with only one neighbor), the problem is to output another leaf string.&#160;<a href=#fnref:13 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref1:13 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:14><p>The existence of solutions for problems in <strong>complexity class PPP:</strong> (also known as Polynomial Pigeonhole Principle) is guaranteed by the pigeonhole principle: if $n$ balls are placed in $m &lt; n$ bins then at least one bin must contain more than one ball.&#160;<a href=#fnref:14 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:15><p>Josh Buresh-Oppenheim, Tsuyoshi Morioka: <strong>Relativized NP Search Problems and Propositional Proof Systems</strong>. CCC 2004: 54-67.&#160;<a href=#fnref:15 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:16><p>Finding a point where Gradient Descent terminates is equivalent to finding a KKT point—when the domain is bounded. Computing a KKT point of a continuously differentiable function over $[0, 1]^2$ is complete for <strong>PPAD</strong> $\cap$ <strong>PLS</strong>.&#160;<a href=#fnref:16 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:17><p>The <strong>EOL</strong> class is a combinatorially defined alternative to the complexity class <strong>CLS</strong> (Continuous Local Search), which contains Gradient Descent and various fixed point problems. <strong>CLS</strong> is the smallest known subclass of <strong>TFNP</strong> not known to be in <strong>P</strong>, and hardness results for it imply hardness results for <strong>PPAD</strong> and <strong>PLS</strong> simultaneously.&#160;<a href=#fnref:17 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:18><p>Prahladh Harsha, Daniel Mitropolsky, and Alon Rosen. Downward Self-Reducibility in TFNP. ITCS 2023. <a href=https://doi.org/10.4230/LIPIcs.ITCS.2023.67 rel=noopener class=external-link target=_blank>DOI</a>.&#160;<a href=#fnref:18 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref1:18 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref2:18 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref3:18 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref4:18 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:19><p>One interesting subclass of <strong>EOL</strong> is <strong>End-Of-Potential-Line</strong> (<strong>EOPL</strong>) where we add the following constraint addition to the <code>EOL</code> problem instance: we are also given a potential function that increases along each edge. It is known that the <code>EOPL</code> problem is complete for <strong>PPAD</strong> $\cap$ <strong>PLS</strong>. Hence <strong>EOPL</strong> = <strong>CLS</strong>, suggesting an equivalence between purely combinatorially defined search problems and real-valued continuous optimisation problems. <a href=https://ora.ox.ac.uk/objects/uuid:67e2d80b-76bf-4b49-9b7d-8bbd91633dd7 rel=noopener class=external-link target=_blank>See this thesis</a> for a detailed perspective on this equivalence.&#160;<a href=#fnref:19 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:20><p>If the graph instance in the <code>EOPL</code> problem has a unique sink, then the problem (and the related complexity class) is known as <strong>UEOPL</strong>. It is an open question if the <code>UEOPL</code> is complete for <strong>PPAD</strong> $\cap$ <strong>PLS</strong>.<sup id=fnref4:18><a href=#fn:18 class=footnote-ref role=doc-noteref>18</a></sup>
Once again, we note that we overload the notations <strong>EOPL</strong> and <strong>UEOPL</strong> to refer to both the problems and their corresponding complexity class.&#160;<a href=#fnref:20 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><footer class=post-footer><h3 class=see-also>Related posts</h3><div class=related><ul><li><a href=/posts/reductions/ target=_blank>An Introduction to Reductions</a> <span class=related-date>（2025-01-01）</span></li></ul></div><ul class=post-tags><li><a href=https://theoretickles.netlify.app/tags/reductions/>Reductions</a></li><li><a href=https://theoretickles.netlify.app/tags/p-np/>P-Np</a></li><li><a href=https://theoretickles.netlify.app/tags/eth/>Eth</a></li><li><a href=https://theoretickles.netlify.app/tags/self-reducibility/>Self-Reducibility</a></li><li><a href=https://theoretickles.netlify.app/tags/search-to-decision/>Search-to-Decision</a></li><li><a href=https://theoretickles.netlify.app/tags/factoring/>Factoring</a></li><li><a href=https://theoretickles.netlify.app/tags/primality/>Primality</a></li><li><a href=https://theoretickles.netlify.app/tags/tfnp/>TFNP</a></li></ul><nav class=paginav><a class=next href=https://theoretickles.netlify.app/posts/reductions/><span class=title>« Prev</span><br><span>An Introduction to Reductions</span>
</a><a class=prev href=https://theoretickles.netlify.app/posts/qary/><span class=title>Next »</span><br><span>$q$-ary Lattices</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Self-Reducibility on x" href="https://x.com/intent/tweet/?text=Self-Reducibility&amp;url=https%3a%2f%2ftheoretickles.netlify.app%2fposts%2fselfreductions%2f&amp;hashtags=reductions%2cp-np%2ceth%2cself-reducibility%2csearch-to-decision%2cfactoring%2cprimality%2cTFNP"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Self-Reducibility on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2ftheoretickles.netlify.app%2fposts%2fselfreductions%2f&amp;title=Self-Reducibility&amp;summary=Self-Reducibility&amp;source=https%3a%2f%2ftheoretickles.netlify.app%2fposts%2fselfreductions%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Self-Reducibility on reddit" href="https://reddit.com/submit?url=https%3a%2f%2ftheoretickles.netlify.app%2fposts%2fselfreductions%2f&title=Self-Reducibility"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Self-Reducibility on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2ftheoretickles.netlify.app%2fposts%2fselfreductions%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Self-Reducibility on whatsapp" href="https://api.whatsapp.com/send?text=Self-Reducibility%20-%20https%3a%2f%2ftheoretickles.netlify.app%2fposts%2fselfreductions%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Self-Reducibility on telegram" href="https://telegram.me/share/url?text=Self-Reducibility&amp;url=https%3a%2f%2ftheoretickles.netlify.app%2fposts%2fselfreductions%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Self-Reducibility on ycombinator" href="https://news.ycombinator.com/submitlink?t=Self-Reducibility&u=https%3a%2f%2ftheoretickles.netlify.app%2fposts%2fselfreductions%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://theoretickles.netlify.app/>Theoretickles</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>